{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t2StDZYQqrWv"
   },
   "source": [
    "<i><b>Public-AI</b></i>\n",
    "\n",
    "# 은닉층 시각화하기\n",
    "\n",
    "\n",
    "### _Objective_\n",
    "\n",
    "* Convolution Layer에서 입력을 어떻게 변형시키는지 이해하기 위해 은닉층을 시각화해보도록 하겠습니다. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "66DnZxEMqrWx"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import get_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CI4To85CqrW3"
   },
   "source": [
    "## Dataset) Cat VS Dog Dataset\n",
    "\n",
    "개와 고양이를 분류하기 위해, 아래와 같이 데이터셋을 준비하였습니다.<Br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"cat-vs-dog\"\n",
    "fpath = get_file(\"cat-vs-dog.zip\", \n",
    "                 \"https://s3.ap-northeast-2.amazonaws.com/pai-datasets/alai-deeplearning/cat-vs-dog.zip\")\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    with ZipFile(fpath,'r') as f:\n",
    "        f.extractall(data_dir)\n",
    "        \n",
    "# 이미지 시각화하기 \n",
    "dog_image = cv2.imread(\n",
    "    os.path.join(data_dir,'train','dog','dog.10000.jpg'))\n",
    "dog_image = cv2.cvtColor(dog_image, cv2.COLOR_BGR2RGB)\n",
    "dog_image = cv2.resize(dog_image, (224,224))\n",
    "\n",
    "cat_image = cv2.imread(\n",
    "    os.path.join(data_dir,'train','cat','cat.10000.jpg'))\n",
    "cat_image = cv2.cvtColor(cat_image, cv2.COLOR_BGR2RGB)\n",
    "cat_image = cv2.resize(cat_image, (224,224))\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.imshow(dog_image)\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.imshow(cat_image)\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "si9OvqR5qrW9"
   },
   "source": [
    "<br><br>\n",
    "\n",
    "# \\[ 은닉층 시각화  \\]\n",
    "---\n",
    "\n",
    "* 딥러닝 모델을 블랙 박스 모델이라고 설명하는 사람들이 많습니다. 어떻게 추론하는 지 그 과정을 해석하기가 매우 어렵기 때문입니다.* <br>\n",
    "* 하지만 Convolution Layer에서는 어떠한 특징을 위주로 뽑아냈는지를 은닉층의 활성화정도를 통해 쉽게 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YeDXHzKeqrW-"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1. Pretrained Model 가져오기\n",
    "\n",
    "이번에도 VGG Network를 가져오도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HP25Cty3qrW-"
   },
   "source": [
    "### (1) VGG 모델 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6wUBL_t-qrW_"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg16 = # \n",
    "\n",
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 은닉층 출력값 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 `block1_conv1`부터 `block5_conv3`까지 각층에서 어떤 출력값을 반환하고 있는지를 보도록 하겠습니다. Keras API를 활용하면 각층의 출력값을 좀더 간단하게 가져올 수 있습니다.<br>\n",
    "`model.summary`에 적힌 이름을 통해, Tensor을 가져올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7A_JFMFPqrXM"
   },
   "outputs": [],
   "source": [
    "# 입력 텐서 가져오기\n",
    "inputs = vgg16.input\n",
    "\n",
    "# 은닉층 텐서 가져오기\n",
    "conv1_1 = vgg16.get_layer('block1_conv1').output\n",
    "conv1_2 = vgg16.get_layer('block1_conv2').output\n",
    "\n",
    "conv2_1 = vgg16.get_layer('block2_conv1').output\n",
    "conv2_2 = vgg16.get_layer('block2_conv2').output\n",
    "\n",
    "conv3_3 = vgg16.get_layer('block3_conv3').output\n",
    "conv4_3 = vgg16.get_layer('block4_conv3').output\n",
    "\n",
    "conv5_3 = vgg16.get_layer('block5_conv3').output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "epuqGN33qrXO"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 2. 은닉층 별 결과 시각화하기\n",
    "\n",
    "* 위에서 가져온 7개의 은닉층의 결과를 시각화 해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nM7JBWMPqrXP"
   },
   "source": [
    "### (1) Block-1 층 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model = Model(vgg16.input, \n",
    "              vgg16.get_layer('block1_conv1').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Td4s3CD0qrXP"
   },
   "outputs": [],
   "source": [
    "prep_image = dog_image.astype(np.float32) - [123.68,116.779,103.939,]\n",
    "\n",
    "hidden_outputs = model.predict(prep_image[None])[0]\n",
    "\n",
    "# (height,width,channel) -> (channel, height, width)\n",
    "hidden_outputs = hidden_outputs.transpose(2,0,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 690
    },
    "colab_type": "code",
    "id": "6Hv7R9FLqrXS",
    "outputId": "fe3f2f6e-9791-4fb0-93ac-722d57224eab"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "\n",
    "num_filters = len(hidden_outputs)\n",
    "rows = int(np.sqrt(num_filters))\n",
    "cols = int(np.ceil(num_filters/rows))\n",
    "\n",
    "for idx, hidden in enumerate(hidden_outputs,1):\n",
    "    ax = fig.add_subplot(rows,cols,idx)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])    \n",
    "    ax.imshow(hidden)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IRQ0KHAVqrXV"
   },
   "source": [
    "첫번째 은닉층에서는 주요한 이미지 특성인 Edge와 Color을 위주로 활성화 함을 알 수 있습니다.<br>\n",
    "특히 개의 몸통 부분에 대한 Edge가 많이 잡혔고, 두 눈에 대해서도 강하게 반응하는 것들이 나타납니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-SbkZxCbqrXW"
   },
   "source": [
    "### (2) Block-2 층 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model = Model(vgg16.input, \n",
    "              vgg16.get_layer('block2_conv2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Td4s3CD0qrXP"
   },
   "outputs": [],
   "source": [
    "prep_image = dog_image.astype(np.float32) - [123.68,116.779,103.939,]\n",
    "\n",
    "hidden_outputs = model.predict(prep_image[None])[0]\n",
    "\n",
    "# (height,width,channel) -> (channel, height, width)\n",
    "hidden_outputs = hidden_outputs.transpose(2,0,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "colab_type": "code",
    "id": "IIDlwIo4qrXY",
    "outputId": "49fec02c-6b2e-4481-9585-3bfeb7e2a039"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "\n",
    "num_filters = len(hidden_outputs)\n",
    "rows = int(np.sqrt(num_filters))\n",
    "cols = int(np.ceil(num_filters/rows))\n",
    "\n",
    "for idx, hidden in enumerate(hidden_outputs,1):\n",
    "    ax = fig.add_subplot(rows,cols,idx)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])    \n",
    "    ax.imshow(hidden)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hoW_Qb2yqrXb"
   },
   "source": [
    "단순한 선과 색이 아니라, 이제는 주름, 곡선 같은 조금 더 복잡한 특성들에 반응하기 시작합니다.<br>\n",
    "Convolution Layer를 4층 정도 지나가면서, 좀 더 넓은 범위의 특성들에 반응하기 때문입니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GHtszPVsqrXc"
   },
   "source": [
    "### (3) Block-3 층 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KQ4u7L3vqrXd"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model = Model(vgg16.input, \n",
    "              vgg16.get_layer('block3_conv3').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_image = dog_image.astype(np.float32) - [123.68,116.779,103.939,]\n",
    "\n",
    "hidden_outputs = model.predict(prep_image[None])[0]\n",
    "\n",
    "# (height,width,channel) -> (channel, height, width)\n",
    "hidden_outputs = hidden_outputs.transpose(2,0,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "colab_type": "code",
    "id": "7pDTTLBLqrXg",
    "outputId": "1d5bf284-4a6f-4303-fc93-4b7073de541c"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "\n",
    "num_filters = len(hidden_outputs)\n",
    "rows = int(np.sqrt(num_filters))\n",
    "cols = int(np.ceil(num_filters/rows))\n",
    "\n",
    "for idx, hidden in enumerate(hidden_outputs,1):\n",
    "    ax = fig.add_subplot(rows,cols,idx)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])    \n",
    "    ax.imshow(hidden)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CCPEMp_UqrXi"
   },
   "source": [
    "상위 층으로 갈수록 활성화는 점점 더 추상적으로 되고 시각적으로 이해하기 어려워집니다. <br>\n",
    "'강아지의 털', '강아지의 다리' 처럼 고수준 개념을 인코딩하기 시작합니다.<br>\n",
    "상위 층의 표현에 가면 갈수록 은닉층에서는 국소적으로 강한 특성을 나타내는 곳이 생기고, 전반적으로는 활성화 정도가 작아집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SAUOA1qBqrXi"
   },
   "source": [
    "### (4) Block-4 층 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model = Model(vgg16.input, \n",
    "              vgg16.get_layer('block4_conv3').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Td4s3CD0qrXP"
   },
   "outputs": [],
   "source": [
    "prep_image = dog_image.astype(np.float32) - [123.68,116.779,103.939,]\n",
    "\n",
    "hidden_outputs = model.predict(prep_image[None])[0]\n",
    "\n",
    "# (height,width,channel) -> (channel, height, width)\n",
    "hidden_outputs = hidden_outputs.transpose(2,0,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "colab_type": "code",
    "id": "IIDlwIo4qrXY",
    "outputId": "49fec02c-6b2e-4481-9585-3bfeb7e2a039"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "\n",
    "num_filters = len(hidden_outputs)\n",
    "rows = int(np.sqrt(num_filters))\n",
    "cols = int(np.ceil(num_filters/rows))\n",
    "\n",
    "for idx, hidden in enumerate(hidden_outputs,1):\n",
    "    ax = fig.add_subplot(rows,cols,idx)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])    \n",
    "    ax.imshow(hidden)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZnU9C2OfqrXn"
   },
   "source": [
    "은닉층 내에서 특정 위치 별로 활성화가 뚜렷하게 발생하고 그 이외의 지점에서는 거의 활성화되지 않은 것을 볼 수 있습니다.<br>\n",
    "높은 층의 활성화는 특정 입력에 관한 시각적 정보가 점점 줄어들고 타깃에 관한 정보가 점점 더 증가합니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A4ng2OUtqrXn"
   },
   "source": [
    "### (5) Block-5 층 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model = Model(vgg16.input, \n",
    "              vgg16.get_layer('block5_conv3').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Td4s3CD0qrXP"
   },
   "outputs": [],
   "source": [
    "prep_image = dog_image.astype(np.float32) - [123.68,116.779,103.939,]\n",
    "\n",
    "hidden_outputs = model.predict(prep_image[None])[0]\n",
    "\n",
    "# (height,width,channel) -> (channel, height, width)\n",
    "hidden_outputs = hidden_outputs.transpose(2,0,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "colab_type": "code",
    "id": "IIDlwIo4qrXY",
    "outputId": "49fec02c-6b2e-4481-9585-3bfeb7e2a039"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "\n",
    "num_filters = len(hidden_outputs)\n",
    "rows = int(np.sqrt(num_filters))\n",
    "cols = int(np.ceil(num_filters/rows))\n",
    "\n",
    "for idx, hidden in enumerate(hidden_outputs,1):\n",
    "    ax = fig.add_subplot(rows,cols,idx)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])    \n",
    "    ax.imshow(hidden)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y1EX8e_MqrXr"
   },
   "source": [
    "최종적으로 나온 이 정보를 바탕으로 모델은 이미지를 분류하게 됩니다.<br>\n",
    "이후 배울 Object Detection에서는 이렇게 고차원으로 인코딩된 정보에서 <br>\n",
    "사물의 위치를 찾게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AoPlptPUqrXs"
   },
   "source": [
    "#  \n",
    "\n",
    "---\n",
    "\n",
    "    Copyright(c) 2019 by Public AI. All rights reserved.<br>\n",
    "    Writen by PAI, SangJae Kang ( rocketgrowthsj@publicai.co.kr )  last updated on 2019/05/15\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "3. 은닉층 시각화하기.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
