{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><b>Public AI</b></i>\n",
    "\n",
    "# Optimizer (2) RMSProp and Adam\n",
    "\n",
    "### _Objective_\n",
    "* RMSProp Optimizer에 대해 배워보겠습니다. <br>\n",
    "* 가장 많이 쓰이는 Adam Optimizer에 대해 배워보겠습니다. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(30)\n",
    "if \"set_random_seed\" in dir(tf.random):\n",
    "    tf.random.set_random_seed(30)\n",
    "else:\n",
    "    tf.random.set_seed(30)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# \\[ 1. RMSProp와 Adam Optimizer이란? \\]\n",
    "\n",
    "----\n",
    "\n",
    "* RMSProp 알고리즘도 모멘텀 알고리즘과 다른 방식으로 Gradient Descent 알고리즘에\n",
    "지수이동평균 수식을 포함한 수식입니다.\n",
    "* Adam 알고리즘은 RMSProp 알고리즘과 Momentum 알고리즘을 결합한 수식입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Gradient Descent Optimizer 수식\n",
    "$$\n",
    "W := W - \\alpha \\frac{\\partial Loss}{\\partial W}\n",
    "$$\n",
    "\n",
    "원래 경사하강법의 수식은 위와 같습니다. 이 수식이 어떻게 변형되는지를 한번 보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. RMSProp Optimizer 수식\n",
    "\n",
    "\n",
    "$$\n",
    "G_{t+1} = \\beta G_{t} + (\\triangledown_{W}J(W_t))^2\\\\\n",
    "W_{t+1} = W_{t} - \\frac{\\alpha}{\\sqrt{G_{t+1}+\\epsilon}}\\cdot \\triangledown_{W}J(W_t)\n",
    "$$\n",
    "* RMSProp은 이전까지 변화해왔던 크기만큼을 나누어줌으로써, 많이 변화한 weight는 세밀하게 조정하도록, 적게 변화한 weight은 크게 조정하도록 설계되었습니다. <br>\n",
    "* 학습 Step에 따라, 변화하는 크기를 조정하기 때문에 적응적 학습률(Adaptive Learning)이라고도 불립니다. <br>\n",
    "\n",
    "![](https://mlfromscratch.com/content/images/2019/12/rmsprop.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. ADAM Optimizer 수식\n",
    "\n",
    "\n",
    "$$\n",
    "m_{t+1} = \\beta_1 m_{t} + (1-\\beta_1)\\triangledown_{w}J(w)\\\\\n",
    "v_{t+1} = \\beta_2 v_{t} + (1-\\beta_2)(\\triangledown_{w}J(w))^2\\\\\n",
    "\\hat m_{t+1} = \\frac{m_{t+1}}{1-\\beta^t_1}\\\\\n",
    "\\hat v_{t+1} = \\frac{v_{t+1}}{1-\\beta^t_2}\\\\\n",
    "w_{t+1} = w_{t} - \\frac{\\alpha}{\\sqrt{\\hat v_t + \\epsilon}}\\hat m_{t+1}\n",
    "$$\n",
    "* Adam 알고리즘은 Momentum알고리즘과 RMSProp 알고리즘을 합쳤습니다.<br>\n",
    "* 이때 지수보정 수식은 지수 편향식과 $(1-\\beta)$ 가중치를 모두 포함한 수식입니다.<br>\n",
    "* 보통 $\\beta_1$로는 0.9, $\\beta_2$로는 0.999, $\\epsilon$ 으로는 $10^{-8}$ 정도의 값을 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Optimizer의 계보\n",
    "---\n",
    "출처 : 하용호, 자습해도 모르겠던 딥러닝, 머리속에 인스톨 시켜드립니다\n",
    "\n",
    "![Imgur](https://i.imgur.com/gjdZ0S5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# \\[ 2. RMSProp와 Adam Optimizer 시각화하기 \\]\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Beale Function Visualization\n",
    "\n",
    "\n",
    "* 최적화 함수(Optimizer)를 평가하기 위해, 보통 Beale Function과 같은 test function을 많이 이용합니다.\n",
    "\n",
    "$$\n",
    "f(w_1,w_2) = (1.5 - w_1 + w_1w_2)^2+(2.25-w_1+w_1w_2^2)^2+(2.625-w_1+w_1w_2^3)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beale(w1, w2):\n",
    "    return ((1.5 - w1 + w1 * w2) ** 2 + \n",
    "            (2.25 - w1 + w1 * w2 ** 2) ** 2 + \n",
    "            (2.625 - w1 + w1 * w2 ** 3) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_beale_plot():\n",
    "    # Beale function을 공간으로 치환한 것을 \n",
    "    xmin, xmax, xstep = -4.5, 4.5, .2\n",
    "    ymin, ymax, ystep = -4.5, 4.5, .2\n",
    "\n",
    "    w1s = np.arange(xmin, xmax, xstep)\n",
    "    w2s = np.arange(ymin, ymax, ystep)\n",
    "\n",
    "    w1, w2 = np.meshgrid(w1s, w2s)\n",
    "    z = beale(w1, w2)\n",
    "\n",
    "    minima = np.array([3., .5])\n",
    "    minima_ = minima.reshape(-1, 1)\n",
    "    z_minima = beale(*minima)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    ax = plt.axes(projection='3d', elev=50, azim=-50)\n",
    "\n",
    "    ax.plot(*minima_, z_minima, 'r*', markersize=10)\n",
    "    ax.plot_surface(w1, w2, z, norm=LogNorm(), rstride=1, cstride=1,\n",
    "                    edgecolor='None', alpha=0.3, cmap=plt.cm.jet)\n",
    "\n",
    "    ax.view_init(30, 10)\n",
    "    ax.set_title(\"Beale Function Visualization\")\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$y$')\n",
    "    ax.set_zlabel('$z$')\n",
    "\n",
    "    ax.set_xlim((xmin, xmax))\n",
    "    ax.set_ylim((ymin, ymax))\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = generate_beale_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RMSProp Optimizer 시각화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) decay가 0.9일 때 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop, SGD\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay = 0.9\n",
    "optimizer = RMSprop(learning_rate=1., decay=decay)\n",
    "\n",
    "start_w1, start_w2 = -2.5, -4.\n",
    "\n",
    "w1 = K.variable(start_w1)\n",
    "w2 = K.variable(start_w2)\n",
    "\n",
    "history = []\n",
    "for i in tqdm(range(300)):\n",
    "    with tf.GradientTape() as tape:\n",
    "        out = beale(w1, w2)\n",
    "    history.append((w1.numpy(), w2.numpy(), out.numpy()))\n",
    "    \n",
    "    variables = [w1, w2]\n",
    "    gradients = tape.gradient(out, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_xs, gd_ys, gd_zs = zip(*history)\n",
    "\n",
    "ax = generate_beale_plot()\n",
    "ax.plot(gd_xs, gd_ys, gd_zs, \n",
    "        label='RMSP(decay={})'.format(decay), \n",
    "        color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) decay에 따른 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = generate_beale_plot()\n",
    "\n",
    "for decay in [0.9,0.99,0.999]:\n",
    "    optimizer = RMSprop(learning_rate=1., decay=decay)\n",
    "\n",
    "    start_w1, start_w2 = -2.5, -4.\n",
    "\n",
    "    w1 = K.variable(start_w1)\n",
    "    w2 = K.variable(start_w2)\n",
    "\n",
    "    history = []\n",
    "    for i in tqdm(range(300)):\n",
    "        with tf.GradientTape() as tape:\n",
    "            out = beale(w1, w2)\n",
    "        history.append((w1.numpy(), w2.numpy(), out.numpy()))\n",
    "\n",
    "        variables = [w1, w2]\n",
    "        gradients = tape.gradient(out, variables)\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    gd_xs, gd_ys, gd_zs = zip(*history)\n",
    "    ax.plot(gd_xs, gd_ys, gd_zs, \n",
    "            label='RMSP(decay={})'.format(decay))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ADAM Optimizer 시각화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1)  Adam optimizer 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=1.)\n",
    "\n",
    "start_w1, start_w2 = -2.5, -4.\n",
    "\n",
    "w1 = K.variable(start_w1)\n",
    "w2 = K.variable(start_w2)\n",
    "\n",
    "history = []\n",
    "for i in tqdm(range(300)):\n",
    "    with tf.GradientTape() as tape:\n",
    "        out = beale(w1, w2)\n",
    "    history.append((w1.numpy(), w2.numpy(), out.numpy()))\n",
    "    \n",
    "    variables = [w1, w2]\n",
    "    gradients = tape.gradient(out, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_xs, gd_ys, gd_zs = zip(*history)\n",
    "\n",
    "ax = generate_beale_plot()\n",
    "ax.plot(gd_xs, gd_ys, gd_zs, \n",
    "        label='RMSP(decay={})'.format(decay), \n",
    "        color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Learning Rate에 따른 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = generate_beale_plot()\n",
    "    \n",
    "for learning_rate in [0.1,0.5,1.]:\n",
    "    optimizer = Adam(learning_rate)\n",
    "\n",
    "    start_w1, start_w2 = -2.5, -4.\n",
    "\n",
    "    w1 = K.variable(start_w1)\n",
    "    w2 = K.variable(start_w2)\n",
    "\n",
    "    history = []\n",
    "    for i in tqdm(range(300)):\n",
    "        with tf.GradientTape() as tape:\n",
    "            out = beale(w1, w2)\n",
    "        history.append((w1.numpy(), w2.numpy(), out.numpy()))\n",
    "\n",
    "        variables = [w1, w2]\n",
    "        gradients = tape.gradient(out, variables)\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "        \n",
    "        gd_xs, gd_ys, gd_zs = zip(*history)\n",
    "\n",
    "\n",
    "    ax.plot(gd_xs, gd_ys, gd_zs, \n",
    "            label='ADAM(learning rate={})'.format(learning_rate))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "\n",
    "---\n",
    "\n",
    "    Copyright(c) 2019 by Public AI. All rights reserved.<br>\n",
    "    Writen by PAI, SangJae Kang ( rocketgrowthsj@publicai.co.kr )  last updated on 2019/04/05\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.0",
   "language": "python",
   "name": "tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
